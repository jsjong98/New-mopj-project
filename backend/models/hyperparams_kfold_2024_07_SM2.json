{
  "sequence_length": 14,
  "hidden_size": 253,
  "num_layers": 4,
  "dropout": 0.36696685558448106,
  "batch_size": 42,
  "learning_rate": 0.007318089653205331,
  "num_epochs": 82,
  "patience": 17,
  "warmup_steps": 141,
  "lr_factor": 0.4408929246798075,
  "lr_patience": 5,
  "min_lr": 4.3553782002471147e-07,
  "loss_alpha": 0.5731942631529884,
  "loss_beta": 0.2986071892943182,
  "loss_gamma": 0.07607183213656063,
  "loss_delta": 0.018940335313913564
}
